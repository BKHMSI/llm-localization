<h1> 
  The LLM Language Network 
  <br>
  A Neuroscientific Approach for Identifying Causally Important Units
</h1>

**Paper Link**: TBD

**Authors**: Badr AlKhamissi, Greta Tuckute, Antoine Bosselut*, Martin Schrimpf*
<p> * Equal Supervision </p>


<div style='text-align: center'>
<img src='assets/language-localization.png'></img>
</div>

> To identify language-selective units, we compare activations in response to sentences versus non-words, and isolate the units that exhibit the strongest sentence selectivity. The same method is used in neuroscience to localize the human brain's language network.

## Usage
TBD


## Abstract

Large language models (LLMs) exhibit remarkable capabilities on not just language tasks, but also various other tasks that are not linguistic in nature, such as logical reasoning and social inferences. In the human brain, neuroscience has identified a core language system that specifically supports language processing. We here ask whether similar specialization for language emerges in LLMs. We identify language-selective units within 5 popular LLMs, using the same localizer experiments that are used in neuroscience. To test the causal role of LLM language units, we systematically lesion the localized units which leads to dramatic performance deficits in language tasks, even with a small number of ablations. Lesioning random units leads to almost no difference in performance, establishing LLM language units as functionally meaningful. Correspondingly, language-selective units are more aligned to brain recordings than randomly selected units. Finally, we investigate whether our localization method applies to other cognitive domains: while we again find specialized networks in LLMs for reasoning and social capabilities, there are substantial differences among models. These findings provide functional and causal evidence for specialization in large language models, and highlight parallels with the functional organization in the brain.

## Citation 
TBD
